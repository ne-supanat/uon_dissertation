{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2e0613fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([0.6988]), tensor([0.6988]), tensor([0.6988]))\n",
      "(tensor([0.6045]), tensor([0.7501]), tensor([0.6695]))\n"
     ]
    }
   ],
   "source": [
    "from bert_score import BERTScorer\n",
    "\n",
    "scorer = BERTScorer(model_type=\"bert-base-uncased\")\n",
    "print(scorer.score(cands=['Perceived Convenience'], refs=['personal habit']))\n",
    "print(scorer.score(cands=['Perceived Convenience'], refs=['convenience']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f33043e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from bert_score import BERTScorer\n",
    "from tabulate import tabulate\n",
    "\n",
    "from models.response_models import ScopeComponent\n",
    "\n",
    "\n",
    "def display(pair_item):\n",
    "    return f\"{pair_item[0]} ({ScopeComponent.get_component_name_from_key(pair_item[1])})\"\n",
    "\n",
    "def calculate_best_code_pairs(reference_codes, candidate_codes, compare_key):\n",
    "    # Calculate sematic similarity score\n",
    "    scorer = BERTScorer(model_type=\"bert-base-uncased\")\n",
    "\n",
    "    reference_items = []\n",
    "    for key, item in reference_codes.items():\n",
    "        if key == \"file\":\n",
    "            continue\n",
    "\n",
    "        for item in item:\n",
    "            reference_items.append((item[compare_key], key))\n",
    "\n",
    "    # print(reference_items)\n",
    "\n",
    "    candidate_items = []\n",
    "    for key, item in candidate_codes.items():\n",
    "        if key == \"file\":\n",
    "            continue\n",
    "\n",
    "        for item in item:\n",
    "            candidate_items.append((item[compare_key], key))\n",
    "\n",
    "    # print(candidate_items)\n",
    "\n",
    "\n",
    "    best_pairs = []\n",
    "\n",
    "    for reference_item in reference_items[:]:\n",
    "        best_score = 0\n",
    "        best_can_item = None\n",
    "        for canidate_item in candidate_items:\n",
    "            if reference_item[1] != canidate_item[1]:\n",
    "                continue\n",
    "\n",
    "            P, R, F1 = scorer.score(\n",
    "                cands=[reference_item[0]], refs=[canidate_item[0]]\n",
    "            )\n",
    "\n",
    "            if F1 > best_score:\n",
    "                best_score = F1\n",
    "                best_can_item = canidate_item\n",
    "\n",
    "        best_pairs.append([reference_item, best_can_item, round(float(best_score), 4)])\n",
    "\n",
    "    table = []\n",
    "    for pair in best_pairs:\n",
    "        table.append((display(pair[0]), display(pair[1]), pair[2]))\n",
    "\n",
    "    print(\n",
    "        tabulate(\n",
    "            table,\n",
    "            headers=[\"Candidate Code\", \"Best Reference Code\", \"Best Score\"],\n",
    "            tablefmt=\"rst\",\n",
    "        )\n",
    "    )\n",
    "    print()\n",
    "    \n",
    "    pairs = [pair[2] for pair in best_pairs]\n",
    "    similar_pair = [pair for pair in pairs if pair >= 0.75]\n",
    "\n",
    "    print(f'Total codes: {len(pairs)}')\n",
    "    print(f'Total similar codes (score >= 0.75): {len(similar_pair)}')\n",
    "    print(f'Mean score: {np.mean(pairs)}')\n",
    "    print()\n",
    "\n",
    "    return best_pairs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "79b05af9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File: data/travel_scope_txt/Stage3_Crediton St Lwrence.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====================================================  ===================================================  ============\n",
      "Candidate Code                                         Best Reference Code                                    Best Score\n",
      "=====================================================  ===================================================  ============\n",
      "cyclists (Actors)                                      Residents Commuters (Actors)                               0.5275\n",
      "tax payers  (Actors)                                   Residents Commuters (Actors)                               0.5725\n",
      "residents  (Actors)                                    Residents Commuters (Actors)                               0.7156\n",
      "pedestrians  (Actors)                                  Residents Commuters (Actors)                               0.571\n",
      "cars (Physical Components)                             Alternative Vehicles (Physical Components)                 0.6933\n",
      "public transport (Physical Components)                 Transportation Infrastructure (Physical Components)        0.6671\n",
      "trains (Physical Components)                           Alternative Vehicles (Physical Components)                 0.5293\n",
      "cycle ways (Physical Components)                       Alternative Vehicles (Physical Components)                 0.5784\n",
      "buses (Physical Components)                            Alternative Vehicles (Physical Components)                 0.6421\n",
      "alternative energy (Physical Components)               Alternative Vehicles (Physical Components)                 0.795\n",
      "motorcycles (Physical Components)                      Alternative Vehicles (Physical Components)                 0.6673\n",
      "courtesy  (Social Aspect)                              Community Safety (Social Aspect)                           0.4122\n",
      "working far from home  (Social Aspect)                 Community Safety (Social Aspect)                           0.3419\n",
      "should reduce polution (Social Aspect)                 Public Awareness Education (Social Aspect)                 0.4297\n",
      "road nightmare (Psychological Aspect)                  Perceived Freedom (Psychological Aspect)                   0.5259\n",
      "change behaviour if reasonable (Psychological Aspect)  Perceived Freedom (Psychological Aspect)                   0.4985\n",
      "efficiency (Psychological Aspect)                      Perceived Freedom (Psychological Aspect)                   0.6688\n",
      "safety (Misc)                                          Environmental Concerns (Misc)                              0.5635\n",
      "carbon emissions  (Misc)                               Environmental Concerns (Misc)                              0.6745\n",
      "rush hour  (Misc)                                      Environmental Concerns (Misc)                              0.4408\n",
      "daily travel (Key Activities)                          Commuting (Key Activities)                                 0.4898\n",
      "holiday travel (Key Activities)                        Policy Implementation (Key Activities)                     0.459\n",
      "=====================================================  ===================================================  ============\n",
      "\n",
      "Total codes: 22\n",
      "Total similar codes (score >= 0.75): 1\n",
      "Mean score: 0.5665318181818182\n",
      "\n",
      "File: data/travel_scope_txt/Stage3_Cullompton North.txt\n",
      "==============================================  =====================================================  ============\n",
      "Candidate Code                                  Best Reference Code                                      Best Score\n",
      "==============================================  =====================================================  ============\n",
      "resident (Actors)                               Travelers (Actors)                                           0.7288\n",
      "big businesses (Actors)                         Government and Policy Makers (Actors)                        0.4967\n",
      "public transport system (Actors)                Government and Policy Makers (Actors)                        0.4201\n",
      "government (Actors)                             Travelers (Actors)                                           0.5987\n",
      "cycling (Physical Components)                   Public Transport Infrastructure (Physical Components)        0.4597\n",
      "walking (Physical Components)                   Public Transport Infrastructure (Physical Components)        0.385\n",
      "train (Physical Components)                     Public Transport Infrastructure (Physical Components)        0.3704\n",
      "bus (Physical Components)                       Public Transport Infrastructure (Physical Components)        0.4656\n",
      "car (Physical Components)                       Public Transport Infrastructure (Physical Components)        0.4772\n",
      "Big business action & policy (Social Aspect)    Convenience and Lifestyle (Social Aspect)                    0.5182\n",
      "depend on car (Social Aspect)                   Convenience and Lifestyle (Social Aspect)                    0.4753\n",
      "car sharing (Social Aspect)                     Convenience and Lifestyle (Social Aspect)                    0.4871\n",
      "individualism (Social Aspect)                   Community and Social Norms (Social Aspect)                   0.5188\n",
      "Environmental awareness (Psychological Aspect)  Fear and Safety (Psychological Aspect)                       0.4864\n",
      "convenience (Psychological Aspect)              Fear and Safety (Psychological Aspect)                       0.3974\n",
      "efficiency (Psychological Aspect)               Fear and Safety (Psychological Aspect)                       0.5124\n",
      "reliability (Psychological Aspect)              Fear and Safety (Psychological Aspect)                       0.5265\n",
      "cost (Psychological Aspect)                     Fear and Safety (Psychological Aspect)                       0.4077\n",
      "responsible (Psychological Aspect)              Fear and Safety (Psychological Aspect)                       0.3964\n",
      "congestion (Misc)                               Environmental Concerns (Misc)                                0.442\n",
      "policy (Misc)                                   Environmental Concerns (Misc)                                0.5226\n",
      "price (Misc)                                    Environmental Concerns (Misc)                                0.4812\n",
      "destination distance (Misc)                     Economic Factors (Misc)                                      0.5058\n",
      "climate (Misc)                                  Environmental Concerns (Misc)                                0.504\n",
      "travel to meet friend (Key Activities)          Commuting (Key Activities)                                   0.4804\n",
      "holiday travel (Key Activities)                 Policy Implementation (Key Activities)                       0.459\n",
      "promote ideas (Key Activities)                  Policy Implementation (Key Activities)                       0.5262\n",
      "==============================================  =====================================================  ============\n",
      "\n",
      "Total codes: 27\n",
      "Total similar codes (score >= 0.75): 0\n",
      "Mean score: 0.4833185185185184\n",
      "\n",
      "File: data/travel_scope_txt/Stage3_Pennsylvania.txt\n",
      "======================================  =====================================================  ============\n",
      "Candidate Code                          Best Reference Code                                      Best Score\n",
      "======================================  =====================================================  ============\n",
      "residents (Actors)                      Individual Travellers (Actors)                               0.6304\n",
      "government (Actors)                     Government and Planners (Actors)                             0.5397\n",
      "cars (Physical Components)              Cars and Scooters (Physical Components)                      0.5279\n",
      "public transport (Physical Components)  Public Transport Infrastructure (Physical Components)        0.8291\n",
      "train (Physical Components)             Public Transport Infrastructure (Physical Components)        0.3704\n",
      "not aware of policy (Social Aspect)     Car Dependency Norms (Social Aspect)                         0.4503\n",
      "reduce carbon emission (Social Aspect)  Public Transport Reliability (Social Aspect)                 0.5149\n",
      "no bus in late night (Social Aspect)    Car Dependency Norms (Social Aspect)                         0.4291\n",
      "family duty (Social Aspect)             Car Dependency Norms (Social Aspect)                         0.6118\n",
      "reliability (Psychological Aspect)      Perceived Convenience (Psychological Aspect)                 0.6694\n",
      "convenience (Psychological Aspect)      Perceived Convenience (Psychological Aspect)                 0.6695\n",
      "cost (Misc)                             Cost of Travel (Misc)                                        0.536\n",
      "the traffic jams (Misc)                 Environmental Concerns (Misc)                                0.5242\n",
      "daily travel (Key Activities)           Commuting (Key Activities)                                   0.4898\n",
      "holiday travel (Key Activities)         Policy Implementation (Key Activities)                       0.459\n",
      "======================================  =====================================================  ============\n",
      "\n",
      "Total codes: 15\n",
      "Total similar codes (score >= 0.75): 1\n",
      "Mean score: 0.5501000000000001\n",
      "\n",
      "File: data/travel_scope_txt/Stage3_Polsloe.txt\n",
      "===================================================================  ========================================================  ============\n",
      "Candidate Code                                                       Best Reference Code                                         Best Score\n",
      "===================================================================  ========================================================  ============\n",
      "residents (Actors)                                                   Cyclists Vulnerability (Actors)                                 0.5762\n",
      "cars (Physical Components)                                           Cycle Path Limitations (Physical Components)                    0.5387\n",
      "bicycle (Physical Components)                                        Cycle Path Limitations (Physical Components)                    0.5528\n",
      "bus (Physical Components)                                            Cycle Path Limitations (Physical Components)                    0.5244\n",
      "car dependency (Social Aspect)                                       Car Dependency Norm (Social Aspect)                             0.7172\n",
      "car sharing (Social Aspect)                                          Car Dependency Norm (Social Aspect)                             0.6978\n",
      "safety (Psychological Aspect)                                        Fear of Cycling (Psychological Aspect)                          0.4629\n",
      "not happy with current public transport cost (Psychological Aspect)  Inconvenience of Public Transport (Psychological Aspect)        0.5412\n",
      "convenience (Psychological Aspect)                                   Fear of Cycling (Psychological Aspect)                          0.3657\n",
      "Congestion (Misc)                                                    Congestion Problems (Misc)                                      0.5384\n",
      "cost (Misc)                                                          Bus Cost (Misc)                                                 0.6862\n",
      "daily travel (Key Activities)                                        Holiday Travel (Key Activities)                                 0.6995\n",
      "holiday travel (Key Activities)                                      Holiday Travel (Key Activities)                                 1\n",
      "===================================================================  ========================================================  ============\n",
      "\n",
      "Total codes: 13\n",
      "Total similar codes (score >= 0.75): 1\n",
      "Mean score: 0.6077692307692308\n",
      "\n",
      "File: data/travel_scope_txt/Stage3_St Loyes.txt\n",
      "=====================================================  ============================================  ============\n",
      "Candidate Code                                         Best Reference Code                             Best Score\n",
      "=====================================================  ============================================  ============\n",
      "Residents (Actors)                                     Travelers (Actors)                                  0.7013\n",
      "Student (Actors)                                       Travelers (Actors)                                  0.7923\n",
      "Government (Actors)                                    Government (Actors)                                 1\n",
      "pedestrians (Actors)                                   Travelers (Actors)                                  0.7161\n",
      "cyclists (Actors)                                      Travelers (Actors)                                  0.5845\n",
      "Walking (Physical Components)                          Private Cars (Physical Components)                  0.3941\n",
      "Bus (Physical Components)                              Private Cars (Physical Components)                  0.464\n",
      "Free Bus Pass (Physical Components)                    Public Transport (Physical Components)              0.5297\n",
      "Bus Fares (Physical Components)                        Public Transport (Physical Components)              0.5996\n",
      "Tram (Physical Components)                             Private Cars (Physical Components)                  0.4815\n",
      "coaches (Physical Components)                          Private Cars (Physical Components)                  0.5234\n",
      "trains (Physical Components)                           Private Cars (Physical Components)                  0.5034\n",
      "cars (Physical Components)                             Private Cars (Physical Components)                  0.6947\n",
      "electric cars (Physical Components)                    Private Cars (Physical Components)                  0.7402\n",
      "plane (Physical Components)                            Private Cars (Physical Components)                  0.4753\n",
      "tax (Physical Components)                              Private Cars (Physical Components)                  0.435\n",
      "Parents took their kids to school (Social Aspect)      Community Norms (Social Aspect)                     0.4099\n",
      "environmental impacts (Social Aspect)                  Community Norms (Social Aspect)                     0.5529\n",
      "company policy (Social Aspect)                         Community Norms (Social Aspect)                     0.6418\n",
      "Motivation (Psychological Aspect)                      Perceived Convenience (Psychological Aspect)        0.6852\n",
      "convenience (Psychological Aspect)                     Perceived Convenience (Psychological Aspect)        0.6695\n",
      "comfortable  (Psychological Aspect)                    Perceived Convenience (Psychological Aspect)        0.6855\n",
      "climate awareness  (Psychological Aspect)              Environmental Concern (Psychological Aspect)        0.7104\n",
      "benefit (Psychological Aspect)                         Perceived Convenience (Psychological Aspect)        0.6016\n",
      "personal habit (Psychological Aspect)                  Perceived Convenience (Psychological Aspect)        0.6988\n",
      "stuborness in older generation (Psychological Aspect)  Perceived Convenience (Psychological Aspect)        0.4714\n",
      "Pollution of the air (Misc)                            Economic Factors (Misc)                             0.4546\n",
      "Congestion (Misc)                                      Geographic Constraints (Misc)                       0.5218\n",
      "carbon omissions (Misc)                                Geographic Constraints (Misc)                       0.4525\n",
      "daily travel (Key Activities)                          Travel Mode Choice (Key Activities)                 0.4925\n",
      "holiday travel (Key Activities)                        Travel Mode Choice (Key Activities)                 0.4783\n",
      "=====================================================  ============================================  ============\n",
      "\n",
      "Total codes: 31\n",
      "Total similar codes (score >= 0.75): 2\n",
      "Mean score: 0.5858645161290322\n",
      "\n",
      "--------------------------------------------------\n",
      "Overall Total Code: 108\n",
      "Overall Total similar codes (score >= 0.75): 5\n",
      "Overall Mean Similarity: 0.5540\n",
      "\n",
      "Actors                   : 0.6357 ± 0.1336\n",
      "Physical Components      : 0.5488 ± 0.1214\n",
      "Social Aspect            : 0.5131 ± 0.1043\n",
      "Psychological Aspect     : 0.5548 ± 0.1129\n",
      "Misc                     : 0.5232 ± 0.0717\n",
      "Key Activities           : 0.5485 ± 0.1569\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Sentiment Analysis: Thematic analysis\n",
    "with open(\"./travel/02_thematic_analysis_codes_human.txt\") as f:\n",
    "    reference_codes_raw = f.read().strip().split(\"\\n\\n\")\n",
    "\n",
    "with open(\"./travel/02_thematic_analysis_codes.txt\") as f:\n",
    "    candidate_codes_raw = f.read().strip().split(\"\\n\\n\")\n",
    "\n",
    "best_pairs = []\n",
    "for i in range(len(candidate_codes_raw)):\n",
    "    reference_codes: dict = json.loads(reference_codes_raw[i])\n",
    "    candidate_codes: dict = json.loads(candidate_codes_raw[i])\n",
    "\n",
    "    print(f'File: {candidate_codes['file']}')\n",
    "    best_pairs += calculate_best_code_pairs(reference_codes, candidate_codes, \"code\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Overall aspect (data from all documents)\n",
    "pairs = [pair[2] for pair in best_pairs]\n",
    "similar_pair = [pair for pair in pairs if pair >= 0.75]\n",
    "\n",
    "print(\"-\"*50)\n",
    "print(f'Overall Total Code: {len(pairs)}')\n",
    "print(f'Overall Total similar codes (score >= 0.75): {len(similar_pair)}')\n",
    "print(f'Overall Mean Similarity: {np.mean(pairs):.4f}')\n",
    "print()\n",
    "\n",
    "# Array of scores of each component\n",
    "score_dict = {}\n",
    "\n",
    "for pair in best_pairs:\n",
    "    component_key = pair[0][1]\n",
    "    score = pair[2]\n",
    "    if component_key not in score_dict:\n",
    "        score_dict[component_key] = []\n",
    "\n",
    "    score_dict[component_key].append(score)\n",
    "\n",
    "for key in  ScopeComponent.get_component_keys():\n",
    "    print('{:<25}: {:.4f} ± {:.4f}'.format(ScopeComponent.get_component_name_from_key(key), np.mean(score_dict[key]), np.std(score_dict[key])))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8de4a7e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================================  ========================================================  ============\n",
      "Candidate Code                                                      Best Reference Code                                         Best Score\n",
      "==================================================================  ========================================================  ============\n",
      "Residents (Actors)                                                  Commuters (Actors)                                              0.6247\n",
      "Walking (Physical Components)                                       Cycling (Physical Components)                                   0.6143\n",
      "Cycling (Physical Components)                                       Cycling (Physical Components)                                   1\n",
      "Cars (Physical Components)                                          Cars (Physical Components)                                      1\n",
      "Public transport (Physical Components)                              Public Transport (Physical Components)                          1\n",
      "Car dependency (Social Aspect)                                      Car Dependency Norms (Social Aspect)                            0.72\n",
      "Reduce carbon emission (Social Aspect)                              Public Transport Reliability (Social Aspect)                    0.5149\n",
      "Ready to change behaviour if it reasonable (Psychological Aspect)   Perceived Convenience (Psychological Aspect)                    0.4455\n",
      "Choose best transport mode on personal view (Psychological Aspect)  Frustration with Public Transport (Psychological Aspect)        0.4713\n",
      "Climate awareness (Psychological Aspect)                            Climate awareness (Psychological Aspect)                        1\n",
      "Carbon emissions level (Misc)                                       Carbon emissions level (Misc)                                   1\n",
      "Daily travel (Key Activities)                                       Commuting (Key Activities)                                      0.4898\n",
      "==================================================================  ========================================================  ============\n",
      "\n",
      "Total codes: 12\n",
      "Total similar codes (score >= 0.75): 5\n",
      "Mean score: 0.7400416666666666\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Sentiment Analysis: EABSS Scope\n",
    "with open(\"./travel/02_eabss_scope_human.txt\") as f:\n",
    "    reference_codes_raw = f.read().strip().split(\"\\n\\n\")[0]\n",
    "\n",
    "with open(\"./travel/02_eabss_scope.txt\") as f:\n",
    "    candidate_codes_raw = f.read().strip().split(\"\\n\\n\")[0]\n",
    "\n",
    "\n",
    "reference_codes: dict = json.loads(reference_codes_raw)\n",
    "candidate_codes: dict = json.loads(candidate_codes_raw)\n",
    "\n",
    "best_pairs = calculate_best_code_pairs(reference_codes, candidate_codes, \"element\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "578803bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([0.4496]), tensor([0.4953]), tensor([0.4713]))\n",
      "(tensor([0.3963]), tensor([0.4622]), tensor([0.4267]))\n"
     ]
    }
   ],
   "source": [
    "from bert_score import BERTScorer\n",
    "\n",
    "scorer = BERTScorer(model_type=\"bert-base-uncased\")\n",
    "print(scorer.score(cands=['Choose best transport mode on personal view'], refs=['Frustration with Public Transport']))\n",
    "print(scorer.score(cands=['Choose best transport mode on personal view'], refs=['Perceived Convenience']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "d496b2b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bert_score import BERTScorer\n",
    "import numpy as np\n",
    "\n",
    "# BERTScore explain and examples\n",
    "# Ref: https://medium.com/@abonia/bertscore-explained-in-5-minutes-0b98553bfb71\n",
    "\n",
    "\n",
    "def calculate_score_full(candidate_text: str, reference_text: str):\n",
    "    # Calculate sematic similarity score\n",
    "    scorer = BERTScorer(model_type=\"bert-base-uncased\")\n",
    "\n",
    "    candidate_sentences = candidate_text.strip()\n",
    "    reference_sentences = reference_text.strip()\n",
    "    \n",
    "    P, R, F1 = scorer.score(cands=[candidate_sentences], refs=[reference_sentences])\n",
    "    return float(F1)\n",
    "\n",
    "def calculate_score_all_to_all(candidate_text: str, reference_text: str):\n",
    "    # Calculate sematic similarity score\n",
    "    scorer = BERTScorer(model_type=\"bert-base-uncased\")\n",
    "\n",
    "    scores = []\n",
    "    candidate_sentences = [c.strip() for c in candidate_text.strip().split(\".\")]\n",
    "    reference_sentences = [r.strip() for r in reference_text.strip().split(\".\")]\n",
    "    \n",
    "    for candidate in candidate_sentences:\n",
    "        if candidate == \"\":\n",
    "            continue\n",
    "        best_score = 0\n",
    "\n",
    "        for reference in reference_sentences:\n",
    "            if reference == \"\":\n",
    "                continue\n",
    "            \n",
    "            # return Precision, Recall, F1\n",
    "            P, R, F1 = scorer.score(cands=[candidate], refs=[reference])\n",
    "            if F1 > best_score:\n",
    "                best_score = F1\n",
    "\n",
    "        scores.append(best_score)\n",
    "        \n",
    "    return np.mean(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "d1e69289",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment analysis between Human and LLM profile summary results\n",
      "File: data/travel_profile_txt/CreditonStLawrence.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/nn/modules/module.py:1520: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[79], line 26\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(file) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m     24\u001b[0m     transcript \u001b[38;5;241m=\u001b[39m f\u001b[38;5;241m.\u001b[39mread()\u001b[38;5;241m.\u001b[39mstrip()\n\u001b[0;32m---> 26\u001b[0m score \u001b[38;5;241m=\u001b[39m \u001b[43mcalculate_score_all_to_all\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreference_summaries\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtranscript\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     27\u001b[0m human_scores\u001b[38;5;241m.\u001b[39mappend(score)\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMean F1 score Human - Original: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mscore\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[78], line 36\u001b[0m, in \u001b[0;36mcalculate_score_all_to_all\u001b[0;34m(candidate_text, reference_text)\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;66;03m# return Precision, Recall, F1\u001b[39;00m\n\u001b[0;32m---> 36\u001b[0m P, R, F1 \u001b[38;5;241m=\u001b[39m \u001b[43mscorer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscore\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcands\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mcandidate\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrefs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mreference\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m F1 \u001b[38;5;241m>\u001b[39m best_score:\n\u001b[1;32m     38\u001b[0m     best_score \u001b[38;5;241m=\u001b[39m F1\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/bert_score/scorer.py:220\u001b[0m, in \u001b[0;36mBERTScorer.score\u001b[0;34m(self, cands, refs, verbose, batch_size, return_hash)\u001b[0m\n\u001b[1;32m    217\u001b[0m     idf_dict[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tokenizer\u001b[38;5;241m.\u001b[39msep_token_id] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    218\u001b[0m     idf_dict[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tokenizer\u001b[38;5;241m.\u001b[39mcls_token_id] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m--> 220\u001b[0m all_preds \u001b[38;5;241m=\u001b[39m \u001b[43mbert_cos_score_idf\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    221\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    222\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrefs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    223\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcands\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    224\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_tokenizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    225\u001b[0m \u001b[43m    \u001b[49m\u001b[43midf_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    226\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    227\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    228\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    229\u001b[0m \u001b[43m    \u001b[49m\u001b[43mall_layers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mall_layers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    230\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mcpu()\n\u001b[1;32m    232\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ref_group_boundaries \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    233\u001b[0m     max_preds \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/bert_score/utils.py:616\u001b[0m, in \u001b[0;36mbert_cos_score_idf\u001b[0;34m(model, refs, hyps, tokenizer, idf_dict, verbose, batch_size, device, all_layers)\u001b[0m\n\u001b[1;32m    614\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch_start \u001b[38;5;129;01min\u001b[39;00m iter_range:\n\u001b[1;32m    615\u001b[0m     sen_batch \u001b[38;5;241m=\u001b[39m sentences[batch_start : batch_start \u001b[38;5;241m+\u001b[39m batch_size]\n\u001b[0;32m--> 616\u001b[0m     embs, masks, padded_idf \u001b[38;5;241m=\u001b[39m \u001b[43mget_bert_embedding\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    617\u001b[0m \u001b[43m        \u001b[49m\u001b[43msen_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midf_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mall_layers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mall_layers\u001b[49m\n\u001b[1;32m    618\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    619\u001b[0m     embs \u001b[38;5;241m=\u001b[39m embs\u001b[38;5;241m.\u001b[39mcpu()\n\u001b[1;32m    620\u001b[0m     masks \u001b[38;5;241m=\u001b[39m masks\u001b[38;5;241m.\u001b[39mcpu()\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/bert_score/utils.py:455\u001b[0m, in \u001b[0;36mget_bert_embedding\u001b[0;34m(all_sens, model, tokenizer, idf_dict, batch_size, device, all_layers)\u001b[0m\n\u001b[1;32m    453\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m    454\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mlen\u001b[39m(all_sens), batch_size):\n\u001b[0;32m--> 455\u001b[0m         batch_embedding \u001b[38;5;241m=\u001b[39m \u001b[43mbert_encode\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    456\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    457\u001b[0m \u001b[43m            \u001b[49m\u001b[43mpadded_sens\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    458\u001b[0m \u001b[43m            \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmask\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    459\u001b[0m \u001b[43m            \u001b[49m\u001b[43mall_layers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mall_layers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    460\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    461\u001b[0m         embeddings\u001b[38;5;241m.\u001b[39mappend(batch_embedding)\n\u001b[1;32m    462\u001b[0m         \u001b[38;5;28;01mdel\u001b[39;00m batch_embedding\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/bert_score/utils.py:351\u001b[0m, in \u001b[0;36mbert_encode\u001b[0;34m(model, x, attention_mask, all_layers)\u001b[0m\n\u001b[1;32m    349\u001b[0m model\u001b[38;5;241m.\u001b[39meval()\n\u001b[1;32m    350\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m--> 351\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mall_layers\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    352\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m all_layers:\n\u001b[1;32m    353\u001b[0m     emb \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstack(out[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:1028\u001b[0m, in \u001b[0;36mBertModel.forward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict, cache_position)\u001b[0m\n\u001b[1;32m   1021\u001b[0m \u001b[38;5;66;03m# Prepare head mask if needed\u001b[39;00m\n\u001b[1;32m   1022\u001b[0m \u001b[38;5;66;03m# 1.0 in head_mask indicate we keep the head\u001b[39;00m\n\u001b[1;32m   1023\u001b[0m \u001b[38;5;66;03m# attention_probs has shape bsz x n_heads x N x N\u001b[39;00m\n\u001b[1;32m   1024\u001b[0m \u001b[38;5;66;03m# input head_mask has shape [num_heads] or [num_hidden_layers x num_heads]\u001b[39;00m\n\u001b[1;32m   1025\u001b[0m \u001b[38;5;66;03m# and head_mask is converted to shape [num_hidden_layers x batch x num_heads x seq_length x seq_length]\u001b[39;00m\n\u001b[1;32m   1026\u001b[0m head_mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_head_mask(head_mask, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mnum_hidden_layers)\n\u001b[0;32m-> 1028\u001b[0m encoder_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1029\u001b[0m \u001b[43m    \u001b[49m\u001b[43membedding_output\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1030\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1031\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1032\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1033\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_extended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1034\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1035\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1036\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1037\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1038\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1039\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1040\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1041\u001b[0m sequence_output \u001b[38;5;241m=\u001b[39m encoder_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1042\u001b[0m pooled_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler(sequence_output) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:675\u001b[0m, in \u001b[0;36mBertEncoder.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict, cache_position)\u001b[0m\n\u001b[1;32m    671\u001b[0m     all_hidden_states \u001b[38;5;241m=\u001b[39m all_hidden_states \u001b[38;5;241m+\u001b[39m (hidden_states,)\n\u001b[1;32m    673\u001b[0m layer_head_mask \u001b[38;5;241m=\u001b[39m head_mask[i] \u001b[38;5;28;01mif\u001b[39;00m head_mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 675\u001b[0m layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mlayer_module\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    676\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    677\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    678\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    679\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# as a positional argument for gradient checkpointing\u001b[39;49;00m\n\u001b[1;32m    680\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    681\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    682\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    683\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    684\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    686\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    687\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m output_attentions:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/transformers/modeling_layers.py:94\u001b[0m, in \u001b[0;36mGradientCheckpointingLayer.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     91\u001b[0m         logger\u001b[38;5;241m.\u001b[39mwarning(message)\n\u001b[1;32m     93\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(partial(\u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs), \u001b[38;5;241m*\u001b[39margs)\n\u001b[0;32m---> 94\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:614\u001b[0m, in \u001b[0;36mBertLayer.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions, cache_position)\u001b[0m\n\u001b[1;32m    611\u001b[0m     attention_output \u001b[38;5;241m=\u001b[39m cross_attention_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    612\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m outputs \u001b[38;5;241m+\u001b[39m cross_attention_outputs[\u001b[38;5;241m1\u001b[39m:]  \u001b[38;5;66;03m# add cross attentions if we output attention weights\u001b[39;00m\n\u001b[0;32m--> 614\u001b[0m layer_output \u001b[38;5;241m=\u001b[39m \u001b[43mapply_chunking_to_forward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    615\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeed_forward_chunk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchunk_size_feed_forward\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mseq_len_dim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_output\u001b[49m\n\u001b[1;32m    616\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    617\u001b[0m outputs \u001b[38;5;241m=\u001b[39m (layer_output,) \u001b[38;5;241m+\u001b[39m outputs\n\u001b[1;32m    619\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m outputs\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/transformers/pytorch_utils.py:251\u001b[0m, in \u001b[0;36mapply_chunking_to_forward\u001b[0;34m(forward_fn, chunk_size, chunk_dim, *input_tensors)\u001b[0m\n\u001b[1;32m    248\u001b[0m     \u001b[38;5;66;03m# concatenate output at same dimension\u001b[39;00m\n\u001b[1;32m    249\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcat(output_chunks, dim\u001b[38;5;241m=\u001b[39mchunk_dim)\n\u001b[0;32m--> 251\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minput_tensors\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:622\u001b[0m, in \u001b[0;36mBertLayer.feed_forward_chunk\u001b[0;34m(self, attention_output)\u001b[0m\n\u001b[1;32m    621\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfeed_forward_chunk\u001b[39m(\u001b[38;5;28mself\u001b[39m, attention_output):\n\u001b[0;32m--> 622\u001b[0m     intermediate_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mintermediate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mattention_output\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    623\u001b[0m     layer_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput(intermediate_output, attention_output)\n\u001b[1;32m    624\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m layer_output\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:539\u001b[0m, in \u001b[0;36mBertIntermediate.forward\u001b[0;34m(self, hidden_states)\u001b[0m\n\u001b[1;32m    538\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, hidden_states: torch\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[0;32m--> 539\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdense\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    540\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mintermediate_act_fn(hidden_states)\n\u001b[1;32m    541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m hidden_states\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/nn/modules/linear.py:116\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 116\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "\n",
    "with open(\"./travel/05_profiles_human.txt\") as f:\n",
    "    reference_profiles_raw = f.read().strip().split(\"\\n\\n\")\n",
    "    reference_profiles = [json.loads(profile_raw) for profile_raw in reference_profiles_raw]\n",
    "    reference_summaries = [profile[\"summary\"] for profile in reference_profiles]\n",
    "\n",
    "with open(\"./travel/05_profiles.txt\") as f:\n",
    "    candidate_profiles_raw = f.read().strip().split(\"\\n\\n\")\n",
    "    candidate_profiles = [json.loads(profile_raw) for profile_raw in candidate_profiles_raw]\n",
    "    candidate_summaries = [profile[\"summary\"] for profile in candidate_profiles]\n",
    "\n",
    "print(\"Sentiment analysis between Human and LLM profile summary results\")\n",
    "human_scores = []\n",
    "llm_scores = []\n",
    "human_llm_scores = []\n",
    "\n",
    "for i in range(len(candidate_summaries)):\n",
    "    file = candidate_profiles[i]['file']\n",
    "    print(f\"File: {file}\")\n",
    "\n",
    "    with open(file) as f:\n",
    "        transcript = f.read().strip()\n",
    "\n",
    "    score = calculate_score_all_to_all(reference_summaries[i], transcript)\n",
    "    human_scores.append(score)\n",
    "    print(f\"Mean F1 score Human - Original: {score:.4f}\")\n",
    "\n",
    "    score = calculate_score_all_to_all(candidate_summaries[i], transcript)\n",
    "    llm_scores.append(score)\n",
    "    print(f\"Mean F1 score LLM - Original: {score:.4f}\")\n",
    "\n",
    "    score = calculate_score_all_to_all(candidate_summaries[i], reference_summaries[i])\n",
    "    human_llm_scores.append(score)\n",
    "    print(f\"Mean F1 score Human - LLM: {score:.4f}\")\n",
    "\n",
    "print(f\"Overall Human - Original Mean F1 score: {np.mean(human_scores):.4f} \")\n",
    "print(f\"Overall LLM -  Original Mean F1 score: {np.mean(llm_scores):.4f} \")\n",
    "print(f\"Overall Human - LLM Mean F1 score: {np.mean(human_llm_scores):.4f} \")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e743ea2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bert_score import BERTScorer\n",
    "\n",
    "scorer = BERTScorer(model_type=\"bert-base-uncased\")\n",
    "cands=\"He is traveling mostly by car but strongly tend to use public transport.He does not care much about cost of travel. he prioritises the experiences more.He needs to go to work at Halsworthy which has no public transport available.He thinks people will change their habit when it not practical anymore.He likes scenario one (improving public transport).but he thinks the quality of busses is more important than frequency and we should stop keep using old buses.He does not like penalty tax policy because the concerns about its transparency of where taxes spent.\"\n",
    "refs=\"The interviewee is a retired economics teacher who travels frequently, both locally and internationally. Cost influences his travel choices, especially for longer journeys where he prefers public transport. He values the convenience of car travel for local trips and work-related travel, despite the cost. He acknowledges the need for change in travel behavior due to congestion and environmental problems but believes change will be driven by necessity rather than personal conviction. He is skeptical of current transport policies and advocates for improved public transport quality and efficiency in cargo transport.\"\n",
    "\n",
    "calculate_score_all_to_all(cands, refs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
